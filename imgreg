import os
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from sklearn.metrics.pairwise import cosine_similarity
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import pytesseract
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from scipy.stats import wasserstein_distance
from tkinter import filedialog, simpledialog, Tk
import tkinter as tk

# Function to load and preprocess an image
def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

# Load ResNet50 pre-trained on ImageNet data (without the top layer)
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the pre-trained layers
for layer in base_model.layers:
    layer.trainable = False

# Set the correct number of classes in your dataset
num_classes = 99  # Replace with the actual number of classes in your dataset ── how much folder do you have in dataset folder....

# Create a new model with a custom top layer for your classification task
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Set the path to your dataset
dataset_path = 'dataset'

# Define data generators with data augmentation
datagen = ImageDataGenerator(
    rescale=1. / 255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Generate training dataset
train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

# Generate validation dataset
validation_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Fine-tune the pre-trained model on your dataset
# Increase the number of epochs
model.fit(
    train_generator,
    epochs=20,  # Increase the number of epochs
    validation_data=validation_generator
)

# Save the embeddings for the dataset
embeddings = []
for img_path in train_generator.filepaths:
    img_array = load_and_preprocess_image(img_path)

    # Get the embedding for each image
    img_embedding = base_model.predict(img_array).reshape(1, -1)
    embeddings.append(img_embedding)

# Save the embeddings to a file
embeddings_array = np.vstack(embeddings)
np.save('dataset_embeddings.npy', embeddings_array)

# Option to either upload an image or capture from the live camera using GUI
root = Tk()
root.withdraw()

# Choose an option dialog
choice = simpledialog.askstring("Input", "Choose an option (1: Upload Image, 2: Capture from Live Camera)")

if choice == '1':
    # Choose a file to upload
    file_path = filedialog.askopenfilename()
    test_image_path = file_path
elif choice == '2':
    # Capture an image from the camera
    cap = cv2.VideoCapture(0)
    ret, frame = cap.read()

    # Save the captured image
    cv2.imwrite('captured_image.jpg', frame)

    # Release the camera
    cap.release()

    test_image_path = 'captured_image.jpg'
else:
    print('Invalid choice. Exiting...')
    root.destroy()
    exit()

# Load the captured image for prediction
img_array = load_and_preprocess_image(test_image_path)

# Get the embedding for the captured image
captured_embedding = base_model.predict(img_array).reshape(1, -1)

# Load dataset embeddings
dataset_embeddings = np.load('dataset_embeddings.npy')

# Calculate cosine similarity between the captured image and dataset images
similarities = cosine_similarity(captured_embedding, dataset_embeddings)

# Display top 5 images with similarity scores
fig, axs = plt.subplots(1, min(5, len(train_generator.filepaths)), figsize=(15, 3))

top_similarity_indices = np.argsort(similarities[0])[-5:][::-1]  # Get indices of top 5 similarities

for i, index in enumerate(top_similarity_indices):
    img_path = train_generator.filepaths[index]
    similarity = similarities[0][index]
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    axs[i].imshow(img)
    axs[i].axis('off')
    axs[i].set_title(f"Similarity: {similarity:.2f}")

plt.show()

# Set a higher similarity threshold to reduce false positives
similarity_threshold = 0.5  # Adjust this threshold based on the printed scores

if np.max(similarities) >= similarity_threshold:
    # If similar, display the most similar image from the dataset
    most_similar_index = np.argmax(similarities)
    most_similar_image_path = train_generator.filepaths[most_similar_index]
    most_similar_img = cv2.imread(most_similar_image_path)
    most_similar_img = cv2.cvtColor(most_similar_img, cv2.COLOR_BGR2RGB)
    plt.imshow(most_similar_img)
    plt.title(f'Most Similar Image')
    plt.axis('off')
    plt.show()

    # Extract text using OCR (Optical Character Recognition)
    brand_text = pytesseract.image_to_string(Image.open(test_image_path))
    print(f'Brand Text: {brand_text}')

    # Perform color analysis using Earth Mover's Distance (EMD)
    captured_hist = cv2.calcHist([img_array[0]], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
    captured_hist = captured_hist.flatten() / captured_hist.sum()

    dataset_img = cv2.imread(most_similar_image_path)
    dataset_hist = cv2.calcHist([dataset_img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
    dataset_hist = dataset_hist.flatten() / dataset_hist.sum()

    # Compare color histograms using Earth Mover's Distance (EMD)
    color_similarity = wasserstein_distance(captured_hist, dataset_hist)

    print(f'Color Similarity: {color_similarity}')

    # Perform object detection (you can use a pre-trained object detection model here)
    # Display detected objects or classes

else:
    print('No similar images found in the dataset.')

# Destroy the Tkinter root window
root.destroy()



Dataset need to like this 
dataset1/
├── class1/
│   ├── image1.jpg
│   ├── image2.jpg
│   └── ...
├── class2/
│   ├── image1.jpg
│   ├── image2.jpg
│   └── ...
└── class3/
    ├── image1.jpg
    ├── image2.jpg
    └── ...


Needed package are 
pip install numpy
pip install matplotlib
pip install scikil-learn
pip install image
pip install tensorflow
pip install opencv-python
pip install pytesseract
pip install keras
pip install scipy if i miss something sorry.


use pycharm the python interperter need 3.8 to 3.11
